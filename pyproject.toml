[build-system]
requires = ["flit_core >=3.2,<4"]
build-backend = "flit_core.buildapi"

[project]
name = "clip_layerwise_alignments"
version = "0.0.1"
description = "This project explores layer-wise alignment in CLIP by training projection layers that map intermediate representations from one encoder to final outputs from the other encoder. The central question: Is alignment a shallow operation on rich representations, or does it require deep semantic processing throughout the network?"
authors = [
  { name = "Juan Cruz Ferreyra" },
]
license = { file = "LICENSE" }
readme = "README.md"
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License"
]
dependencies = [
    "black",
    "flake8",
    "isort",
    "mkdocs",
    "pip",
    "pytest",
    "python-dotenv",
    "pyyaml (>=6.0.2,<7.0.0)",
    "tqdm (>=4.67.1,<5.0.0)",
    "numpy (>=2,<2.3.0)",
    "pillow (>=11.3.0,<12.0.0)",
    "torch (>=2.7.1,<3.0.0)",
    "torchvision (>=0.22.1)",
    "ftfy (>=6.1.0,<7.0.0)",
    "regex (>=2023.0.0)",
    "requests (>=2.31.0,<3.0.0)",
    "kaggle (>=1.5.0,<2.0.0)",
    "ipykernel (>=6.30.1,<7.0.0)",
    "matplotlib (>=3.7.0,<4.0.0)",
    "numpy (>=2,<2.3.0)",
    "supervision (==0.26.1)",
    "opencv-python (>=4.12.0.88,<5.0.0.0)",
    "open-clip-torch (>=3.2.0,<4.0.0)",
]
requires-python = "~=3.11.0"

[tool.black]
line-length = 99
include = '\.pyi?$'
exclude = '''
/(
    \.git
  | \.venv
)/
'''

[tool.isort]
profile = "black"
known_first_party = ["classification_training"]
force_sort_within_sections = true

[[tool.poetry.source]]
name = "pytorch_gpu"
url = "https://download.pytorch.org/whl/cu128"
priority = "explicit"

[tool.poetry.dependencies]
torch = { source = "pytorch_gpu" }
torchvision = { source = "pytorch_gpu" }


